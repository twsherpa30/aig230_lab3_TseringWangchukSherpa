{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc81b3e",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) — Notebook 1: Text Representation\n",
    "\n",
    "This notebook focuses on **turning raw text into numeric features** you can use in real-world ML systems.\n",
    "\n",
    "You will build:\n",
    "- a clean **train/test split**\n",
    "- **Bag-of-Words** (binary and count)\n",
    "- **Document-Term Matrix** (DTM)\n",
    "- **TF-IDF** (with n-grams)\n",
    "- **Hashing trick** (production-friendly)\n",
    "- basic **retrieval** (cosine similarity) and a **baseline classifier**\n",
    "- model **persistence** (save/load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31f235f",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe2bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ad879",
   "metadata": {},
   "source": [
    "## 1) A small, realistic dataset (you can replace with your own CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88fd94a",
   "metadata": {},
   "source": [
    "In industry, text often comes with:\n",
    "- an **ID**\n",
    "- free-text **description**\n",
    "- a **label** (category, priority, intent, topic) or a target (churn, fraud, etc.)\n",
    "\n",
    "Here we create a toy dataset that looks like support tickets / ops incidents.  \n",
    "Swap this section with a `pd.read_csv(...)` in your own workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2912b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-001</td>\n",
       "      <td>VPN keeps disconnecting every 10 minutes on Wi...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-002</td>\n",
       "      <td>Password reset link is expired and user cannot...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-003</td>\n",
       "      <td>Email delivery delayed, outbound messages queu...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T-004</td>\n",
       "      <td>Cannot install printer driver, installer fails...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-005</td>\n",
       "      <td>MFA prompt never arrives on mobile app, user s...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T-006</td>\n",
       "      <td>WiFi signal drops in meeting rooms, access poi...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T-007</td>\n",
       "      <td>Outlook search not returning results, index se...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T-008</td>\n",
       "      <td>Laptop battery drains fast after BIOS update, ...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T-009</td>\n",
       "      <td>Portal shows 500 error when submitting form, h...</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T-010</td>\n",
       "      <td>API requests timing out, latency spike observe...</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T-011</td>\n",
       "      <td>User cannot access shared drive, permission de...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T-012</td>\n",
       "      <td>Teams calls have choppy audio, jitter high on ...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T-013</td>\n",
       "      <td>Push notifications not working on Android for ...</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T-014</td>\n",
       "      <td>Mailbox is full and cannot receive emails, aut...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T-015</td>\n",
       "      <td>Bluetooth mouse not pairing after restart, dev...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                               text      label\n",
       "0      T-001  VPN keeps disconnecting every 10 minutes on Wi...    network\n",
       "1      T-002  Password reset link is expired and user cannot...       auth\n",
       "2      T-003  Email delivery delayed, outbound messages queu...  messaging\n",
       "3      T-004  Cannot install printer driver, installer fails...     device\n",
       "4      T-005  MFA prompt never arrives on mobile app, user s...       auth\n",
       "5      T-006  WiFi signal drops in meeting rooms, access poi...    network\n",
       "6      T-007  Outlook search not returning results, index se...  messaging\n",
       "7      T-008  Laptop battery drains fast after BIOS update, ...     device\n",
       "8      T-009  Portal shows 500 error when submitting form, h...        app\n",
       "9      T-010  API requests timing out, latency spike observe...        app\n",
       "10     T-011  User cannot access shared drive, permission de...       auth\n",
       "11     T-012  Teams calls have choppy audio, jitter high on ...    network\n",
       "12     T-013  Push notifications not working on Android for ...        app\n",
       "13     T-014  Mailbox is full and cannot receive emails, aut...  messaging\n",
       "14     T-015  Bluetooth mouse not pairing after restart, dev...     device"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = [\n",
    "    (\"T-001\", \"VPN keeps disconnecting every 10 minutes on Windows 11 after latest update\", \"network\"),\n",
    "    (\"T-002\", \"Password reset link is expired and user cannot login to the portal\", \"auth\"),\n",
    "    (\"T-003\", \"Email delivery delayed, outbound messages queued for hours\", \"messaging\"),\n",
    "    (\"T-004\", \"Cannot install printer driver, installer fails with error code 1603\", \"device\"),\n",
    "    (\"T-005\", \"MFA prompt never arrives on mobile app, user stuck at login\", \"auth\"),\n",
    "    (\"T-006\", \"WiFi signal drops in meeting rooms, access point reboot helps temporarily\", \"network\"),\n",
    "    (\"T-007\", \"Outlook search not returning results, index seems corrupted\", \"messaging\"),\n",
    "    (\"T-008\", \"Laptop battery drains fast after BIOS update, power settings unchanged\", \"device\"),\n",
    "    (\"T-009\", \"Portal shows 500 error when submitting form, happened after deployment\", \"app\"),\n",
    "    (\"T-010\", \"API requests timing out, latency spike observed in last hour\", \"app\"),\n",
    "    (\"T-011\", \"User cannot access shared drive, permission denied though in correct group\", \"auth\"),\n",
    "    (\"T-012\", \"Teams calls have choppy audio, jitter high on corporate network\", \"network\"),\n",
    "    (\"T-013\", \"Push notifications not working on Android for the app\", \"app\"),\n",
    "    (\"T-014\", \"Mailbox is full and cannot receive emails, auto-archive not running\", \"messaging\"),\n",
    "    (\"T-015\", \"Bluetooth mouse not pairing after restart, device shows as unknown\", \"device\"),\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"ticket_id\", \"text\", \"label\"])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e16c08",
   "metadata": {},
   "source": [
    "### Train/test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b923b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10\n",
      "Test size: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.33, random_state=42, stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Test size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe83e41",
   "metadata": {},
   "source": [
    "## 2) Tokenization basics and normalization (lightweight, practical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ac38a",
   "metadata": {},
   "source": [
    "In production pipelines you typically do **minimal, safe normalization**:\n",
    "- lowercase\n",
    "- normalize whitespace\n",
    "- optionally strip obvious punctuation\n",
    "- keep numbers when they carry meaning (error codes, versions, dates)\n",
    "\n",
    "Heavy normalization (stemming, aggressive regexes) can hurt when your text includes:\n",
    "error codes, product names, IDs, or domain terminology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517e7b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>text_norm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T-001</td>\n",
       "      <td>vpn keeps disconnecting every 10 minutes on wi...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-002</td>\n",
       "      <td>password reset link is expired and user cannot...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-003</td>\n",
       "      <td>email delivery delayed, outbound messages queu...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T-004</td>\n",
       "      <td>cannot install printer driver, installer fails...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-005</td>\n",
       "      <td>mfa prompt never arrives on mobile app, user s...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_id                                          text_norm      label\n",
       "0     T-001  vpn keeps disconnecting every 10 minutes on wi...    network\n",
       "1     T-002  password reset link is expired and user cannot...       auth\n",
       "2     T-003  email delivery delayed, outbound messages queu...  messaging\n",
       "3     T-004  cannot install printer driver, installer fails...     device\n",
       "4     T-005  mfa prompt never arrives on mobile app, user s...       auth"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def simple_normalize(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df[\"text_norm\"] = df[\"text\"].map(simple_normalize)\n",
    "df[[\"ticket_id\",\"text_norm\",\"label\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8087e",
   "metadata": {},
   "source": [
    "## 3) Vocabulary + Document-Term Matrix (DTM) with CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cad1ae",
   "metadata": {},
   "source": [
    "**CountVectorizer** builds:\n",
    "- a vocabulary (token → column index)\n",
    "- a sparse matrix where rows are documents and columns are tokens\n",
    "\n",
    "This is the classic **Document-Term Matrix** representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e35424b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape (train): (10, 92)\n",
      "Vocabulary size: 92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count_vec = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",  # keeps tokens like \"500\", \"1603\", \"mfa\"\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "X_train_counts = count_vec.fit_transform(X_train)\n",
    "X_test_counts  = count_vec.transform(X_test)\n",
    "\n",
    "print(\"DTM shape (train):\", X_train_counts.shape)\n",
    "print(\"Vocabulary size:\", len(count_vec.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03137003",
   "metadata": {},
   "source": [
    "### Inspect the vocabulary and a single row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48545c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 0),\n",
       " ('11', 1),\n",
       " ('1603', 2),\n",
       " ('500', 3),\n",
       " ('access', 4),\n",
       " ('after', 5),\n",
       " ('and', 6),\n",
       " ('api', 7),\n",
       " ('app', 8),\n",
       " ('archive', 9),\n",
       " ('arrives', 10),\n",
       " ('at', 11),\n",
       " ('auto', 12),\n",
       " ('battery', 13),\n",
       " ('bios', 14),\n",
       " ('cannot', 15),\n",
       " ('code', 16),\n",
       " ('correct', 17),\n",
       " ('corrupted', 18),\n",
       " ('denied', 19),\n",
       " ('deployment', 20),\n",
       " ('disconnecting', 21),\n",
       " ('drains', 22),\n",
       " ('drive', 23),\n",
       " ('driver', 24)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Show a small slice of the vocabulary (token -> index)\n",
    "vocab_items = sorted(count_vec.vocabulary_.items(), key=lambda x: x[1])[:25]\n",
    "vocab_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e5357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('portal', 1),\n",
       " ('shows', 1),\n",
       " ('500', 1),\n",
       " ('error', 1),\n",
       " ('when', 1),\n",
       " ('submitting', 1),\n",
       " ('form', 1),\n",
       " ('happened', 1),\n",
       " ('after', 1),\n",
       " ('deployment', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Look at a specific document row: non-zero entries (token counts)\n",
    "row_id = 0\n",
    "row = X_train_counts[row_id]\n",
    "inv_vocab = {idx: tok for tok, idx in count_vec.vocabulary_.items()}\n",
    "\n",
    "nz_cols = row.nonzero()[1]\n",
    "tokens_counts = sorted([(inv_vocab[c], int(row[0, c])) for c in nz_cols], key=lambda x: -x[1])\n",
    "tokens_counts[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4094",
   "metadata": {},
   "source": [
    "## 4) Binary vs Count-based Bag-of-Words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e35af",
   "metadata": {},
   "source": [
    "Binary BoW: token present or not (good for short texts and some classification tasks)  \n",
    "Count BoW: raw frequency (baseline for many pipelines)\n",
    "\n",
    "Both discard word order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8060cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_vec = CountVectorizer(binary=True, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X_train_bin = binary_vec.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59977e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 92)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b888da90",
   "metadata": {},
   "source": [
    "## 5) TF-IDF (a refinement, not a replacement)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10e225",
   "metadata": {},
   "source": [
    "TF-IDF downweights very common tokens and upweights tokens that are more distinctive.\n",
    "\n",
    "In industry, TF-IDF with **n-grams** is a strong baseline for:\n",
    "- ticket routing\n",
    "- intent detection\n",
    "- spam detection\n",
    "- incident clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2dfd321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(\n",
    "    ngram_range = (1,2),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    min_df=1,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_train_tfidf = tfidf_vec.fit_transform(X_train)\n",
    "X_test_tfidf  = tfidf_vec.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4897a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF DTM shape (train): (10, 186)\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF DTM shape (train):\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d8d93",
   "metadata": {},
   "source": [
    "## 6) Quick retrieval: 'find similar tickets' with cosine similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51871c0e",
   "metadata": {},
   "source": [
    "A very common industry use case is **nearest neighbor retrieval** for:\n",
    "- deduplication\n",
    "- suggesting knowledge base articles\n",
    "- finding similar past incidents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae445ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_all = tfidf_vec.transform(df[\"text\"])\n",
    "\n",
    "def search_similar(query: str, top_k: int = 3):\n",
    "    query_vec = tfidf_vec.transform([query])\n",
    "    sims = cosine_similarity(query_vec, X_all).ravel()\n",
    "    top_idx = np.argsort(sims)[-top_k:]\n",
    "    return df.iloc[top_idx][[\"ticket_id\", \"text\", \"label\"]].assign(similarity= sims[top_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488cc10",
   "metadata": {},
   "source": [
    "## 7) Classification baseline (Logistic Regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a481a",
   "metadata": {},
   "source": [
    "For text classification, a strong baseline is:\n",
    "\n",
    "**TF-IDF → Linear model (LogReg / Linear SVM)**\n",
    "\n",
    "This is fast, reliable, easy to explain, and often hard to beat without deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19b472a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         app       0.00      0.00      0.00         1\n",
      "        auth       0.50      1.00      0.67         1\n",
      "      device       0.00      0.00      0.00         1\n",
      "   messaging       0.00      0.00      0.00         1\n",
      "     network       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.30      0.40      0.33         5\n",
      "weighted avg       0.30      0.40      0.33         5\n",
      "\n",
      "Confusion matrix:\n",
      " [[0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"model\", clf)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3b2be",
   "metadata": {},
   "source": [
    "## 8) Production pattern: HashingVectorizer (no stored vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aadab9",
   "metadata": {},
   "source": [
    "In production, you may need:\n",
    "- constant memory usage\n",
    "- privacy (no vocabulary inspection)\n",
    "- streaming support\n",
    "- easier deployment across services\n",
    "\n",
    "**HashingVectorizer** avoids building a vocabulary. Tradeoff: collisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c023926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         app       0.00      0.00      0.00         1\n",
      "        auth       1.00      1.00      1.00         1\n",
      "      device       0.00      0.00      0.00         1\n",
      "   messaging       0.00      0.00      0.00         1\n",
      "     network       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.40      0.40      0.40         5\n",
      "weighted avg       0.40      0.40      0.40         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "hash_pipe = Pipeline([\n",
    "    (\"hash\", HashingVectorizer(\n",
    "        n_features=2**18,        # tune for your scale\n",
    "        alternate_sign=False,    # makes features more interpretable for linear models\n",
    "        ngram_range=(1,2),\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\"\n",
    "    )),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "hash_pipe.fit(X_train, y_train)\n",
    "pred_hash = hash_pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred_hash))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae2433",
   "metadata": {},
   "source": [
    "## 9) Save and load the model (typical deployment step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"week3_text_representation_model.joblib\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "loaded = joblib.load(model_path)\n",
    "loaded.predict([\"portal returns 500 error after deploy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fffc4fb",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 10 more tickets to `data` with realistic wording and labels. Re-train and compare results.  \n",
    "2) Try `ngram_range=(1,3)` and observe what changes.  \n",
    "3) For retrieval, test at least 3 queries and explain why the top result makes sense.  \n",
    "4) Replace the dataset with a CSV you create (columns: `text`, `label`) and rerun the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc36ce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 15\n",
      "Expanded dataset size: 25\n",
      "\n",
      "Label distribution in expanded dataset:\n",
      "label\n",
      "network      6\n",
      "auth         5\n",
      "device       5\n",
      "app          5\n",
      "messaging    4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample new tickets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>T-021</td>\n",
       "      <td>SMTP relay rejected, cannot send external emai...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>T-022</td>\n",
       "      <td>USB drive not recognized by Windows, shows as ...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>T-023</td>\n",
       "      <td>Single sign-on fails when accessing third-part...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>T-024</td>\n",
       "      <td>Server disk space at 95 percent, cleanup neede...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>T-025</td>\n",
       "      <td>Load balancer health check failing, traffic no...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                               text      label\n",
       "20     T-021  SMTP relay rejected, cannot send external emai...  messaging\n",
       "21     T-022  USB drive not recognized by Windows, shows as ...     device\n",
       "22     T-023  Single sign-on fails when accessing third-part...       auth\n",
       "23     T-024  Server disk space at 95 percent, cleanup neede...     device\n",
       "24     T-025  Load balancer health check failing, traffic no...    network"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1: Add 10 more tickets with realistic wording and labels\n",
    "new_tickets = [\n",
    "    (\"T-016\", \"Database connection pool exhausted, application cannot connect to DB\", \"app\"),\n",
    "    (\"T-017\", \"SSL certificate expired on internal web server, HTTPS fails\", \"network\"),\n",
    "    (\"T-018\", \"Two-factor authentication code not sent to registered phone number\", \"auth\"),\n",
    "    (\"T-019\", \"Firewall blocking outbound traffic on port 443, web requests failing\", \"network\"),\n",
    "    (\"T-020\", \"Application crashes with out of memory error during peak load\", \"app\"),\n",
    "    (\"T-021\", \"SMTP relay rejected, cannot send external emails from company domain\", \"messaging\"),\n",
    "    (\"T-022\", \"USB drive not recognized by Windows, shows as unknown device\", \"device\"),\n",
    "    (\"T-023\", \"Single sign-on fails when accessing third-party application\", \"auth\"),\n",
    "    (\"T-024\", \"Server disk space at 95 percent, cleanup needed urgently\", \"device\"),\n",
    "    (\"T-025\", \"Load balancer health check failing, traffic not routing properly\", \"network\"),\n",
    "]\n",
    "\n",
    "# Combine with original data\n",
    "expanded_data = data + new_tickets\n",
    "df_expanded = pd.DataFrame(expanded_data, columns=[\"ticket_id\", \"text\", \"label\"])\n",
    "\n",
    "print(f\"Original dataset size: {len(data)}\")\n",
    "print(f\"Expanded dataset size: {len(df_expanded)}\")\n",
    "print(f\"\\nLabel distribution in expanded dataset:\")\n",
    "print(df_expanded['label'].value_counts())\n",
    "print(f\"\\nSample new tickets:\")\n",
    "df_expanded.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "074edacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original dataset - Train/Test: 10/5\n",
      "Expanded dataset - Train/Test: 16/9\n",
      "\n",
      "--- Original Model Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         app       0.00      0.00      0.00         1\n",
      "        auth       0.50      1.00      0.67         1\n",
      "      device       0.00      0.00      0.00         1\n",
      "   messaging       0.00      0.00      0.00         1\n",
      "     network       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.30      0.40      0.33         5\n",
      "weighted avg       0.30      0.40      0.33         5\n",
      "\n",
      "\n",
      "--- Expanded Model Performance ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         app       0.00      0.00      0.00         2\n",
      "        auth       0.00      0.00      0.00         2\n",
      "      device       1.00      0.50      0.67         2\n",
      "   messaging       0.00      0.00      0.00         1\n",
      "     network       0.25      1.00      0.40         2\n",
      "\n",
      "    accuracy                           0.33         9\n",
      "   macro avg       0.25      0.30      0.21         9\n",
      "weighted avg       0.28      0.33      0.24         9\n",
      "\n",
      "\n",
      "Conclusion: More training data improves model robustness and may improve accuracy,\n",
      "especially for underrepresented classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Retrain with expanded dataset\n",
    "X_train_exp, X_test_exp, y_train_exp, y_test_exp = train_test_split(\n",
    "    df_expanded[\"text\"], df_expanded[\"label\"], test_size=0.33, random_state=42, stratify=df_expanded[\"label\"]\n",
    ")\n",
    "\n",
    "# Retrain pipeline with same hyperparameters\n",
    "pipeline_exp = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipeline_exp.fit(X_train_exp, y_train_exp)\n",
    "pred_exp = pipeline_exp.predict(X_test_exp)\n",
    "print(f\"\\nOriginal dataset - Train/Test: {len(X_train)}/{len(X_test)}\")\n",
    "print(f\"Expanded dataset - Train/Test: {len(X_train_exp)}/{len(X_test_exp)}\")\n",
    "print(\"\\n--- Original Model Performance ---\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"\\n--- Expanded Model Performance ---\")\n",
    "print(classification_report(y_test_exp, pred_exp))\n",
    "print(\"\\nConclusion: More training data improves model robustness and may improve accuracy,\")\n",
    "print(\"especially for underrepresented classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e41fd1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary size with ngram_range=(1,2): 276\n",
      "Vocabulary size with ngram_range=(1,3): 403\n",
      "Increase: 127 features\n",
      "\n",
      "Sample trigrams (3-word sequences):\n",
      "  - 10 minutes on\n",
      "  - 11 after latest\n",
      "  - access point reboot\n",
      "  - access shared drive\n",
      "  - after bios update\n",
      "  - after latest update\n",
      "  - and cannot receive\n",
      "  - android for the\n",
      "  - api requests timing\n",
      "  - app user stuck\n",
      "  - application crashes with\n",
      "  - archive not running\n",
      "  - arrives on mobile\n",
      "  - as unknown device\n",
      "  - authentication code not\n",
      "\n",
      "--- Performance Comparison ---\n",
      "Bigram (1,2) Accuracy:  0.3333\n",
      "Trigram (1,3) Accuracy: 0.3333\n",
      "\n",
      "Bigram (1,2) F1 (weighted):  0.2370\n",
      "Trigram (1,3) F1 (weighted): 0.2370\n",
      "\n",
      "Observations:\n",
      "- Trigrams capture longer phrases (e.g., 'cannot connect to db')\n",
      "- More features = potential for overfitting on small datasets\n",
      "- Trigrams help when exact 3-word phrases are discriminative\n",
      "- May not improve much on short texts or small training sets\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Try ngram_range=(1,3) and observe changes\n",
    "\n",
    "# Original: ngram_range=(1,2)\n",
    "tfidf_bigram = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_train_bigram = tfidf_bigram.fit_transform(X_train_exp)\n",
    "\n",
    "# New: ngram_range=(1,3)\n",
    "tfidf_trigram = TfidfVectorizer(\n",
    "    ngram_range=(1,3),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_train_trigram = tfidf_trigram.fit_transform(X_train_exp)\n",
    "\n",
    "print(f\"\\nVocabulary size with ngram_range=(1,2): {len(tfidf_bigram.vocabulary_):,}\")\n",
    "print(f\"Vocabulary size with ngram_range=(1,3): {len(tfidf_trigram.vocabulary_):,}\")\n",
    "print(f\"Increase: {len(tfidf_trigram.vocabulary_) - len(tfidf_bigram.vocabulary_):,} features\")\n",
    "\n",
    "# Compare some trigrams\n",
    "trigram_features = [feat for feat in tfidf_trigram.get_feature_names_out() if len(feat.split()) == 3]\n",
    "print(f\"\\nSample trigrams (3-word sequences):\")\n",
    "for tg in trigram_features[:15]:\n",
    "    print(f\"  - {tg}\")\n",
    "\n",
    "# Train models with both settings\n",
    "pipeline_bigram = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), token_pattern=r\"(?u)\\b\\w+\\b\", sublinear_tf=True)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipeline_trigram = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,3), token_pattern=r\"(?u)\\b\\w+\\b\", sublinear_tf=True)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipeline_bigram.fit(X_train_exp, y_train_exp)\n",
    "pipeline_trigram.fit(X_train_exp, y_train_exp)\n",
    "\n",
    "pred_bigram = pipeline_bigram.predict(X_test_exp)\n",
    "pred_trigram = pipeline_trigram.predict(X_test_exp)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(f\"\\n--- Performance Comparison ---\")\n",
    "print(f\"Bigram (1,2) Accuracy:  {accuracy_score(y_test_exp, pred_bigram):.4f}\")\n",
    "print(f\"Trigram (1,3) Accuracy: {accuracy_score(y_test_exp, pred_trigram):.4f}\")\n",
    "print(f\"\\nBigram (1,2) F1 (weighted):  {f1_score(y_test_exp, pred_bigram, average='weighted'):.4f}\")\n",
    "print(f\"Trigram (1,3) F1 (weighted): {f1_score(y_test_exp, pred_trigram, average='weighted'):.4f}\")\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Trigrams capture longer phrases (e.g., 'cannot connect to db')\")\n",
    "print(\"- More features = potential for overfitting on small datasets\")\n",
    "print(\"- Trigrams help when exact 3-word phrases are discriminative\")\n",
    "print(\"- May not improve much on short texts or small training sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0678972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query 1: 'user login failed authentication problem' ---\n",
      "ticket_id                                                               text label  similarity\n",
      "    T-005        MFA prompt never arrives on mobile app, user stuck at login  auth    0.208839\n",
      "    T-002 Password reset link is expired and user cannot login to the portal  auth    0.204465\n",
      "    T-018 Two-factor authentication code not sent to registered phone number  auth    0.151879\n",
      "\n",
      "Explanation:\n",
      "Top result likely contains 'login', 'user', 'authentication' or related terms.\n",
      "TF-IDF gives high weight to these domain-specific keywords.\n",
      "Cosine similarity finds tickets with overlapping vocabulary.\n",
      "\n",
      "\n",
      "--- Query 2: 'network connection drops frequently' ---\n",
      "ticket_id                                                                      text   label  similarity\n",
      "    T-016      Database connection pool exhausted, application cannot connect to DB     app    0.145624\n",
      "    T-012           Teams calls have choppy audio, jitter high on corporate network network    0.134693\n",
      "    T-006 WiFi signal drops in meeting rooms, access point reboot helps temporarily network    0.127720\n",
      "\n",
      "Explanation:\n",
      "Results should include 'network', 'connection', 'disconnect', or 'drops'.\n",
      "Terms like 'VPN', 'WiFi', or 'firewall' are semantically related to network issues.\n",
      "Bigrams like 'connection pool' or 'network traffic' boost similarity.\n",
      "\n",
      "\n",
      "--- Query 3: 'device driver installation error' ---\n",
      "ticket_id                                                                text  label  similarity\n",
      "    T-004 Cannot install printer driver, installer fails with error code 1603 device    0.254166\n",
      "    T-015  Bluetooth mouse not pairing after restart, device shows as unknown device    0.123927\n",
      "    T-022        USB drive not recognized by Windows, shows as unknown device device    0.123856\n",
      "\n",
      "Explanation:\n",
      "Top matches contain 'device', 'driver', 'install', or 'error' keywords.\n",
      "Exact matches on rare terms like 'driver' or error codes increase similarity.\n",
      "This demonstrates how TF-IDF-based retrieval works for ticket deduplication.\n",
      "\n",
      "\n",
      "--- Summary ---\n",
      "Cosine similarity with TF-IDF is effective for:\n",
      "  ✓ Finding similar tickets (deduplication)\n",
      "  ✓ Suggesting knowledge base articles\n",
      "  ✓ Routing to similar historical incidents\n",
      "  ✓ Fast, interpretable, no training required\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Test retrieval with 3 queries and explain results\n",
    "# Update search function to use expanded dataset\n",
    "tfidf_retrieval = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    sublinear_tf=True\n",
    ")\n",
    "X_all_exp = tfidf_retrieval.fit_transform(df_expanded[\"text\"])\n",
    "\n",
    "def search_similar_exp(query: str, top_k: int = 3):\n",
    "    query_vec = tfidf_retrieval.transform([query])\n",
    "    sims = cosine_similarity(query_vec, X_all_exp).ravel()\n",
    "    top_idx = np.argsort(sims)[-top_k:][::-1]  # Reverse to get highest first\n",
    "    results = df_expanded.iloc[top_idx][[\"ticket_id\", \"text\", \"label\"]].copy()\n",
    "    results['similarity'] = sims[top_idx]\n",
    "    return results\n",
    "\n",
    "# Test Query 1: Authentication/login issues\n",
    "query1 = \"user login failed authentication problem\"\n",
    "print(f\"\\n--- Query 1: '{query1}' ---\")\n",
    "results1 = search_similar_exp(query1, top_k=3)\n",
    "print(results1.to_string(index=False))\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"Top result likely contains 'login', 'user', 'authentication' or related terms.\")\n",
    "print(\"TF-IDF gives high weight to these domain-specific keywords.\")\n",
    "print(\"Cosine similarity finds tickets with overlapping vocabulary.\")\n",
    "\n",
    "# Test Query 2: Network connectivity issues\n",
    "query2 = \"network connection drops frequently\"\n",
    "print(f\"\\n\\n--- Query 2: '{query2}' ---\")\n",
    "results2 = search_similar_exp(query2, top_k=3)\n",
    "print(results2.to_string(index=False))\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"Results should include 'network', 'connection', 'disconnect', or 'drops'.\")\n",
    "print(\"Terms like 'VPN', 'WiFi', or 'firewall' are semantically related to network issues.\")\n",
    "print(\"Bigrams like 'connection pool' or 'network traffic' boost similarity.\")\n",
    "\n",
    "# Test Query 3: Device/hardware issues\n",
    "query3 = \"device driver installation error\"\n",
    "print(f\"\\n\\n--- Query 3: '{query3}' ---\")\n",
    "results3 = search_similar_exp(query3, top_k=3)\n",
    "print(results3.to_string(index=False))\n",
    "print(\"\\nExplanation:\")\n",
    "print(\"Top matches contain 'device', 'driver', 'install', or 'error' keywords.\")\n",
    "print(\"Exact matches on rare terms like 'driver' or error codes increase similarity.\")\n",
    "print(\"This demonstrates how TF-IDF-based retrieval works for ticket deduplication.\")\n",
    "\n",
    "print(\"\\n\\n--- Summary ---\")\n",
    "print(\"Cosine similarity with TF-IDF is effective for:\")\n",
    "print(\"  ✓ Finding similar tickets (deduplication)\")\n",
    "print(\"  ✓ Suggesting knowledge base articles\")\n",
    "print(\"  ✓ Routing to similar historical incidents\")\n",
    "print(\"  ✓ Fast, interpretable, no training required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6823d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created CSV file: custom_tickets.csv\n",
      "Dataset size: 20 tickets\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "app          7\n",
      "network      4\n",
      "device       4\n",
      "auth         3\n",
      "messaging    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Successfully loaded 20 tickets from CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Application server crashed with Java heap spac...</td>\n",
       "      <td>app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User account locked after multiple failed logi...</td>\n",
       "      <td>auth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Network latency spike affecting all cloud serv...</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email attachment size exceeds maximum allowed ...</td>\n",
       "      <td>messaging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Printer queue stuck, jobs not printing to shar...</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      label\n",
       "0  Application server crashed with Java heap spac...        app\n",
       "1  User account locked after multiple failed logi...       auth\n",
       "2  Network latency spike affecting all cloud serv...    network\n",
       "3  Email attachment size exceeds maximum allowed ...  messaging\n",
       "4  Printer queue stuck, jobs not printing to shar...     device"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4: Create a CSV file and reload the notebook workflow\n",
    "# Create a CSV file with custom data\n",
    "import os\n",
    "\n",
    "csv_data = {\n",
    "    'text': [\n",
    "        \"Application server crashed with Java heap space error\",\n",
    "        \"User account locked after multiple failed login attempts\",\n",
    "        \"Network latency spike affecting all cloud services\",\n",
    "        \"Email attachment size exceeds maximum allowed limit\",\n",
    "        \"Printer queue stuck, jobs not printing to shared printer\",\n",
    "        \"VPN tunnel established but no traffic flowing through\",\n",
    "        \"Mobile app crashes on startup after latest iOS update\",\n",
    "        \"Database transaction timeout during batch processing\",\n",
    "        \"Access denied when trying to mount network share drive\",\n",
    "        \"API rate limit exceeded, requests being throttled\",\n",
    "        \"Bluetooth keyboard disconnects randomly during use\",\n",
    "        \"Certificate validation failed for internal web service\",\n",
    "        \"Spam filter blocking legitimate business emails\",\n",
    "        \"Screen resolution incorrect after docking laptop\",\n",
    "        \"Container orchestration node became unresponsive\",\n",
    "        \"Password complexity requirements not clearly communicated\",\n",
    "        \"File sync service not uploading local changes to cloud\",\n",
    "        \"Load balancer not distributing traffic evenly across servers\",\n",
    "        \"Webcam not detected in video conferencing application\",\n",
    "        \"API gateway returning 502 bad gateway intermittently\"\n",
    "    ],\n",
    "    'label': [\n",
    "        'app', 'auth', 'network', 'messaging', 'device',\n",
    "        'network', 'app', 'app', 'auth', 'app',\n",
    "        'device', 'network', 'messaging', 'device', 'app',\n",
    "        'auth', 'app', 'network', 'device', 'app'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_csv = pd.DataFrame(csv_data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = \"custom_tickets.csv\"\n",
    "df_csv.to_csv(csv_path, index=False)\n",
    "print(f\"Created CSV file: {csv_path}\")\n",
    "print(f\"Dataset size: {len(df_csv)} tickets\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_csv['label'].value_counts())\n",
    "\n",
    "# Load from CSV (simulating real workflow)\n",
    "df_loaded = pd.read_csv(csv_path)\n",
    "print(f\"\\n✓ Successfully loaded {len(df_loaded)} tickets from CSV\")\n",
    "df_loaded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265f592a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 13, Test size: 7\n",
      "TF-IDF vocabulary size: 175\n",
      "Feature matrix shape: (13, 175)\n",
      "\n",
      "--- Classification Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         app       0.43      1.00      0.60         3\n",
      "        auth       0.00      0.00      0.00         1\n",
      "      device       0.00      0.00      0.00         1\n",
      "   messaging       0.00      0.00      0.00         1\n",
      "     network       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43         7\n",
      "   macro avg       0.09      0.20      0.12         7\n",
      "weighted avg       0.18      0.43      0.26         7\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]]\n",
      "\n",
      "--- Retrieval Test ---\n",
      "Query: 'application error memory issue'\n",
      "                                                    text  label  similarity\n",
      "   Application server crashed with Java heap space error    app    0.343898\n",
      "   Webcam not detected in video conferencing application device    0.160396\n",
      "User account locked after multiple failed login attempts   auth    0.000000\n",
      "\n",
      "✓ Model saved to: csv_text_model.joblib\n",
      "Model loaded successfully\n",
      "Sample prediction for 'database connection failed': app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/wangchu/Documents/NLPLabs/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Rerun the entire workflow with CSV data\n",
    "# 1. Train/test split\n",
    "X_train_csv, X_test_csv, y_train_csv, y_test_csv = train_test_split(\n",
    "    df_loaded[\"text\"], df_loaded[\"label\"], test_size=0.33, random_state=42, stratify=df_loaded[\"label\"]\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train_csv)}, Test size: {len(X_test_csv)}\")\n",
    "\n",
    "# 2. TF-IDF Vectorization\n",
    "tfidf_csv = TfidfVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    "    sublinear_tf=True,\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "X_train_tfidf_csv = tfidf_csv.fit_transform(X_train_csv)\n",
    "X_test_tfidf_csv = tfidf_csv.transform(X_test_csv)\n",
    "\n",
    "print(f\"TF-IDF vocabulary size: {len(tfidf_csv.vocabulary_)}\")\n",
    "print(f\"Feature matrix shape: {X_train_tfidf_csv.shape}\")\n",
    "\n",
    "# 3. Train classifier\n",
    "pipeline_csv = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1,2), token_pattern=r\"(?u)\\b\\w+\\b\", sublinear_tf=True)),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_csv.fit(X_train_csv, y_train_csv)\n",
    "pred_csv = pipeline_csv.predict(X_test_csv)\n",
    "\n",
    "print(f\"\\n--- Classification Results ---\")\n",
    "print(classification_report(y_test_csv, pred_csv))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_csv, pred_csv))\n",
    "\n",
    "# 4. Test retrieval on CSV dataset\n",
    "X_all_csv = tfidf_csv.transform(df_loaded[\"text\"])\n",
    "\n",
    "def search_csv(query: str, top_k: int = 3):\n",
    "    query_vec = tfidf_csv.transform([query])\n",
    "    sims = cosine_similarity(query_vec, X_all_csv).ravel()\n",
    "    top_idx = np.argsort(sims)[-top_k:][::-1]\n",
    "    results = df_loaded.iloc[top_idx][[\"text\", \"label\"]].copy()\n",
    "    results['similarity'] = sims[top_idx]\n",
    "    return results\n",
    "\n",
    "print(f\"\\n--- Retrieval Test ---\")\n",
    "test_query = \"application error memory issue\"\n",
    "print(f\"Query: '{test_query}'\")\n",
    "print(search_csv(test_query, top_k=3).to_string(index=False))\n",
    "\n",
    "# 5. Save model\n",
    "csv_model_path = \"csv_text_model.joblib\"\n",
    "joblib.dump(pipeline_csv, csv_model_path)\n",
    "print(f\"\\n✓ Model saved to: {csv_model_path}\")\n",
    "\n",
    "# 6. Load and test\n",
    "loaded_csv_model = joblib.load(csv_model_path)\n",
    "sample_prediction = loaded_csv_model.predict([\"database connection failed\"])\n",
    "print(f\"Model loaded successfully\")\n",
    "print(f\"Sample prediction for 'database connection failed': {sample_prediction[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
